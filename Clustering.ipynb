{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iranian Tweet EDA and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/iranian_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1122936 entries, 0 to 1122935\n",
      "Data columns (total 31 columns):\n",
      "tweetid                     1122936 non-null int64\n",
      "userid                      1122936 non-null object\n",
      "user_display_name           1122936 non-null object\n",
      "user_screen_name            1122936 non-null object\n",
      "user_reported_location      887669 non-null object\n",
      "user_profile_description    995845 non-null object\n",
      "user_profile_url            434954 non-null object\n",
      "follower_count              1122936 non-null int64\n",
      "following_count             1122936 non-null int64\n",
      "account_creation_date       1122936 non-null object\n",
      "account_language            1122936 non-null object\n",
      "tweet_language              1117307 non-null object\n",
      "tweet_text                  1122936 non-null object\n",
      "tweet_time                  1122936 non-null object\n",
      "tweet_client_name           1100078 non-null object\n",
      "in_reply_to_tweetid         339350 non-null float64\n",
      "in_reply_to_userid          440244 non-null object\n",
      "quoted_tweet_tweetid        23369 non-null float64\n",
      "is_retweet                  1122936 non-null bool\n",
      "retweet_userid              232337 non-null object\n",
      "retweet_tweetid             232337 non-null float64\n",
      "latitude                    32 non-null float64\n",
      "longitude                   32 non-null float64\n",
      "quote_count                 1121572 non-null float64\n",
      "reply_count                 1121572 non-null float64\n",
      "like_count                  1121572 non-null float64\n",
      "retweet_count               1121572 non-null float64\n",
      "hashtags                    885731 non-null object\n",
      "urls                        1115553 non-null object\n",
      "user_mentions               685556 non-null object\n",
      "poll_choices                387 non-null object\n",
      "dtypes: bool(1), float64(9), int64(3), object(18)\n",
      "memory usage: 258.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['userid','tweet_language','tweet_text','is_retweet','hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.is_retweet==False)&(df.tweet_language=='en')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize & Lemmatize, Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf vectorizer takes care of stop words; it's on us to remove links, punctuation (can include in token pattern?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = set(string.punctuation+'‘’…°–—“”')\n",
    "lem = nltk.stem.WordNetLemmatizer()\n",
    "twt = TweetTokenizer(reduce_len=True, strip_handles=True)\n",
    "\n",
    "def tweet_tokenize_full(tweet):\n",
    "    tokens = twt.tokenize(tweet)\n",
    "    no_punc = [token for token in tokens if (token[0] not in punc) and (len(token)>2)]\n",
    "    no_links = [token for token in no_punc if token[0:4]!='http']\n",
    "    lemmatized = [lem.lemmatize(token) for token in no_links]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = 1000\n",
    "ngrams = (1,1)\n",
    "vctr = TfidfVectorizer(analyzer='word',\n",
    "                       stop_words='english',\n",
    "                       tokenizer=tweet_tokenize_full,\n",
    "                       max_features=num_feats,\n",
    "                       ngram_range=ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vctr.fit_transform(df.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vals = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vctr.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_results = pd.DataFrame(data = tfidf_vals, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "nmf = NMF(n_components=n_components, random_state=1, alpha=0.1, solver='mu', max_iter=1000, l1_ratio=0.5).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        print(\"Topic #{0}: \\n{1}\\n\".format(topic_idx, top_words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 15\n",
    "print_top_words(nmf, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
